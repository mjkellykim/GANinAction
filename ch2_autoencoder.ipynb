{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch2_autoencoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLb1b25Zcp2dynrDl2rLU3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjkellykim/GANinAction/blob/main/ch2_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgfwzXCJRrUX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# GAN in Action p57\n",
        "# 책에서는 tensorflow 2.2.0 버전에서 테스트\n",
        "# 현재 서버는 2.8.0 \n",
        "# Multi-backend Keras는 공식적으로 2.4부터 지원하지 않음...(?)\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining the key parameters\n",
        "batch_size = 100\n",
        "original_dim = 784 # MNIST 이미지의 높이X너비\n",
        "latent_dim = 2\n",
        "intermediate_dim = 256\n",
        "epochs = 50\n",
        "epsilon_std = 1.0"
      ],
      "metadata": {
        "id": "vi54xDl1RwN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining Sampling Function\n",
        "def sampling(args: tuple):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., \n",
        "                              stddev=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon"
      ],
      "metadata": {
        "id": "g2MR5s_zMUk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining Encoder\n",
        "# input to the encoder 인코더 입력값 \n",
        "x = Input(shape=(original_dim,), name='input')\n",
        "# intermediate layer 중간층\n",
        "h = Dense(intermediate_dim, activation='relu', name=\"encoding\")(x) \n",
        "# defining the mean of the latent space 잠재 공간의 평균 정의\n",
        "z_mean = Dense(latent_dim, name=\"mean\")(h)\n",
        "# defining the log variance of the latent space 잠재 공간의 로그 분산 정의\n",
        "z_log_var = Dense(latent_dim, name=\"log-variance\")(h)\n",
        "# note that \"output_shape\" isn't nesassary with the Tensorflow backend\n",
        "# 텐서플로 백엔드를 사용할 때는 output_shape가 꼭 필요하진 않음\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean,z_log_var]) \n",
        "# print out summery of what we just did\n",
        "encoder = Model(x, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "m8kMWrOaRy-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining Decoder\n",
        "# input to the decoder 디코더 입력\n",
        "input_decoder = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
        "# taking the latent space to intermediate dimension 잠재 공간을 중간층의 차원으로 변환\n",
        "decoder_h = Dense(intermediate_dim, activation='relu', name=\"decoder_h\")(input_decoder)\n",
        "# getting the mean from the original dimension 원본 차원으로 변환\n",
        "x_decoded = Dense(original_dim, activation='sigmoid', name=\"flat_decoded\")(decoder_h) \n",
        "# defining the decoder as a keras model\n",
        "decoder = Model(input_decoder, x_decoded, name=\"decoder\")\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "AhkP9XqfSKuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Variational AutoEncoder\n",
        "# grab the output. Recall. that we need to grab the 3rd element our sample z\n",
        "# 인코더의 출력을 디코더에서 사용, 인코더의 3번째 반환값이 z임!\n",
        "output_combined = decoder(encoder(x)[2]) \n",
        "# link the input and the overall output 입력과 출력을 연결\n",
        "vae = Model(x, output_combined) \n",
        "vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScB024G0SU-a",
        "outputId": "77f2a331-87cf-4cb1-9ab3-70a3ed49d2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 784)]             0         \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 2),               201988    \n",
            "                              (None, 2),                         \n",
            "                              (None, 2)]                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 784)               202256    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 404,244\n",
            "Trainable params: 404,244\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Defining Loss Function\n",
        "kl_loss = -0.5 * K.sum(1 + z_log_var - K.exp(z_log_var) - K.square(z_mean), axis=-1)\n",
        "vae.add_loss(K.mean(kl_loss) / 784.)\n",
        "vae.compile(optimizer='rmsprop', loss=\"binary_crossentropy\") # 모델 컴파일\n",
        "vae.summary()\n",
        "# 이진 교차 엔트로피 (Binary Cross-Entropy)와 쿨백-라이블러 발산(Kullback-Leibler Divergence; KL 발산)을 더해서 전체 손실을 만듦.\n",
        "# * KL 발산은 분포간 차이를 측정함 - 두 분 포의 부피를 계산한 다음 겹치는 부분의 부피를 측정\n",
        "# * 이진 교차 엔트로피는 클래스가 두 개인 분류 문제에서 사용하는 전형적인 손실 함수 중 하나\n",
        "\n",
        "# 위 모델은 RMSprop를 이용하여 컴파일 하지만, Adam이나 SGD(Stochastic Gradient descent-확률적 경사 하강법) 사용 가능 \n",
        "# 다른 딥러닝 시스템과 같이 오차를 역전파하여 파라미터 공간을 탐색함. 항상 경사 하강법을 사용하지만 Adam, SGD, RMSprop 이외를 사용하는 것은 드문 일"
      ],
      "metadata": {
        "id": "2uAKS5x2SXWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 훈련/테스트 세트 분할 및 정규화\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
      ],
      "metadata": {
        "id": "VB7U7gzoSaPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 실제처럼 정렬되지 않은 데이터셋을 위해 데이터를 섞는(shuffle) 옵션과 함께 fit 메서트 적용\n",
        "vae.fit(x_train, x_train, \n",
        "        shuffle=True, \n",
        "        epochs=epochs, \n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7YWSApASdUa",
        "outputId": "f3b76e1c-1fb6-4300-e896-a9c0b6bce50b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "600/600 [==============================] - 8s 12ms/step - loss: 0.2438\n",
            "Epoch 2/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.2171\n",
            "Epoch 3/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.2125\n",
            "Epoch 4/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.2097\n",
            "Epoch 5/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.2077\n",
            "Epoch 6/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.2062\n",
            "Epoch 7/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.2048\n",
            "Epoch 8/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.2035\n",
            "Epoch 9/50\n",
            "600/600 [==============================] - 7s 11ms/step - loss: 0.2023\n",
            "Epoch 10/50\n",
            "600/600 [==============================] - 7s 11ms/step - loss: 0.2011\n",
            "Epoch 11/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.2002\n",
            "Epoch 12/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1994\n",
            "Epoch 13/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1987\n",
            "Epoch 14/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1982\n",
            "Epoch 15/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1976\n",
            "Epoch 16/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1971\n",
            "Epoch 17/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1967\n",
            "Epoch 18/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1962\n",
            "Epoch 19/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1959\n",
            "Epoch 20/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1955\n",
            "Epoch 21/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1951\n",
            "Epoch 22/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1948\n",
            "Epoch 23/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1945\n",
            "Epoch 24/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1942\n",
            "Epoch 25/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1940\n",
            "Epoch 26/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1937\n",
            "Epoch 27/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1935\n",
            "Epoch 28/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1933\n",
            "Epoch 29/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1930\n",
            "Epoch 30/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1928\n",
            "Epoch 31/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1926\n",
            "Epoch 32/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1924\n",
            "Epoch 33/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1923\n",
            "Epoch 34/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1921\n",
            "Epoch 35/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1919\n",
            "Epoch 36/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1918\n",
            "Epoch 37/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1916\n",
            "Epoch 38/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1914\n",
            "Epoch 39/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1913\n",
            "Epoch 40/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1911\n",
            "Epoch 41/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1910\n",
            "Epoch 42/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1909\n",
            "Epoch 43/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1907\n",
            "Epoch 44/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1906\n",
            "Epoch 45/50\n",
            "600/600 [==============================] - 8s 13ms/step - loss: 0.1905\n",
            "Epoch 46/50\n",
            "600/600 [==============================] - 8s 13ms/step - loss: 0.1903\n",
            "Epoch 47/50\n",
            "600/600 [==============================] - 8s 13ms/step - loss: 0.1902\n",
            "Epoch 48/50\n",
            "600/600 [==============================] - 8s 13ms/step - loss: 0.1901\n",
            "Epoch 49/50\n",
            "600/600 [==============================] - 8s 13ms/step - loss: 0.1900\n",
            "Epoch 50/50\n",
            "600/600 [==============================] - 7s 12ms/step - loss: 0.1899\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f05c49a1190>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## display a 2D plot of the digit classes in the latent space\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)[0]\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(x_test_encoded[:,0], x_test_encoded[:,1], c=y_test, cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ti7iJoPFSfUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display a 2D manifold of the digits\n",
        "from scipy.stats import norm\n",
        "n = 15\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure, cmap='Greys_r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AoiLZuugSggO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}